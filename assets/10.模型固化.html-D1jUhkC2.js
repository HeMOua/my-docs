import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as e,o as n}from"./app-BDhRxcGH.js";const t={};function h(l,i){return n(),a("div",null,i[0]||(i[0]=[e(`<h1 id="模型固化" tabindex="-1"><a class="header-anchor" href="#模型固化"><span>模型固化</span></a></h1><p>固化网络输出的结果</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">myseed </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 42069</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # set a random seed for reproducibility</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.backends.cudnn.deterministic </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> True</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.backends.cudnn.benchmark </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">np.random.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(myseed)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(myseed)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">is_available</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">manual_seed_all</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(myseed)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>设置 <code>torch.backends.cudnn.benchmark=True</code> 将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。适用场景是网络结构固定（不是动态变化的），网络的输入形状（包括 batch size，图片大小，输入的通道）是不变的，其实也就是一般情况下都比较适用。反之，如果卷积层的设置一直变化，将会导致程序不停地做优化，反而会耗费更多的时间。</p><p>如果在 PyTorch 程序中设置了 torch.backends.cudnn.deterministic=True，并且 cudnn.benchmark == False的话，那么就选那个默认的卷积算法</p><p>详情见<a href="https://zhuanlan.zhihu.com/p/73711222" target="_blank" rel="noopener noreferrer">torch.backends.cudnn.benchmark</a></p>`,6)]))}const d=s(t,[["render",h],["__file","10.模型固化.html.vue"]]),k=JSON.parse('{"path":"/knowledge/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PyTorch/10.%E6%A8%A1%E5%9E%8B%E5%9B%BA%E5%8C%96.html","title":"模型固化","lang":"zh-CN","frontmatter":{"description":"模型固化 固化网络输出的结果 设置 torch.backends.cudnn.benchmark=True 将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。适用场景是网络结构固定（不是动态变化的），网络的输入形状（包括 batch size，图片大小，输入的通道）是不变的，其实也就是一般情况下都...","head":[["meta",{"property":"og:url","content":"https://jishuzhaix.cn/knowledge/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PyTorch/10.%E6%A8%A1%E5%9E%8B%E5%9B%BA%E5%8C%96.html"}],["meta",{"property":"og:site_name","content":"技数斋"}],["meta",{"property":"og:title","content":"模型固化"}],["meta",{"property":"og:description","content":"模型固化 固化网络输出的结果 设置 torch.backends.cudnn.benchmark=True 将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。适用场景是网络结构固定（不是动态变化的），网络的输入形状（包括 batch size，图片大小，输入的通道）是不变的，其实也就是一般情况下都..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-17T14:21:20.000Z"}],["meta",{"property":"article:modified_time","content":"2025-02-17T14:21:20.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"模型固化\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-17T14:21:20.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"贺墨于\\",\\"url\\":\\"https://jishuzhaix.cn\\"}]}"]]},"headers":[],"git":{"createdTime":1739802080000,"updatedTime":1739802080000,"contributors":[{"name":"HeMOu","username":"HeMOu","email":"fangqichenchao@163.com","commits":1,"url":"https://github.com/HeMOu"}]},"readingTime":{"minutes":0.73,"words":218},"filePathRelative":"knowledge/人工智能/PyTorch/10.模型固化.md","localizedDate":"2025年2月17日","excerpt":"\\n<p>固化网络输出的结果</p>\\n<div class=\\"language-python line-numbers-mode\\" data-highlighter=\\"shiki\\" data-ext=\\"python\\" data-title=\\"python\\" style=\\"--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34\\"><pre class=\\"shiki shiki-themes one-light one-dark-pro vp-code\\"><code><span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">myseed </span><span style=\\"--shiki-light:#383A42;--shiki-dark:#56B6C2\\">=</span><span style=\\"--shiki-light:#986801;--shiki-dark:#D19A66\\"> 42069</span><span style=\\"--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic\\">  # set a random seed for reproducibility</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">torch.backends.cudnn.deterministic </span><span style=\\"--shiki-light:#383A42;--shiki-dark:#56B6C2\\">=</span><span style=\\"--shiki-light:#986801;--shiki-dark:#D19A66\\"> True</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">torch.backends.cudnn.benchmark </span><span style=\\"--shiki-light:#383A42;--shiki-dark:#56B6C2\\">=</span><span style=\\"--shiki-light:#986801;--shiki-dark:#D19A66\\"> False</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">np.random.</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#61AFEF\\">seed</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">(myseed)</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">torch.</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#61AFEF\\">manual_seed</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">(myseed)</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#A626A4;--shiki-dark:#C678DD\\">if</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\"> torch.cuda.</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#61AFEF\\">is_available</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">():</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">    torch.cuda.</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#61AFEF\\">manual_seed_all</span><span style=\\"--shiki-light:#383A42;--shiki-dark:#ABB2BF\\">(myseed)</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}');export{d as comp,k as data};
