import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a,o as i}from"./app-BDhRxcGH.js";const l="/assets/image-20240626112716458-Cje8IufK.png",r="/assets/image-20240626112925398-tQHwfNzJ.png",o="/assets/image-20240626154704476-DJaG02Cv.png",g="/assets/image-20240626154823925-DD_FBsLi.png",s={};function d(c,e){return i(),n("div",null,e[0]||(e[0]=[a('<h1 id="了解大模型" tabindex="-1"><a class="header-anchor" href="#了解大模型"><span>了解大模型</span></a></h1><blockquote><p>AGl(Artificial General inteligence)：通用人工智能</p><p>AI可能的问题：幻觉</p></blockquote><h2 id="生成机制" tabindex="-1"><a class="header-anchor" href="#生成机制"><span>生成机制</span></a></h2><table><thead><tr><th>架构</th><th>设计者</th><th>特点</th></tr></thead><tbody><tr><td>Transformer</td><td>Google</td><td>最流行，几乎所有大模型都用它</td></tr><tr><td>RWKV</td><td>PENG BO</td><td>可并行训练，推理性能极佳，适合在端侧使用</td></tr><tr><td>Mamba</td><td>CMU &amp; Princeton University</td><td>性能更佳，尤其适合长文本生成</td></tr></tbody></table><p>目前只有 transformer 被证明了符合 scaling-law。</p><blockquote><p>定义：Scaling-law（尺度定律）在大语言模型中指的是一种观察到的现象，即当模型规模（如参数量、训练数据量等）增加时，模型的性能（如预测准确性、生成文本的质量等）也会以某种方式提升。</p><p>核心要点：</p><ul><li><strong>模型规模与性能的关系</strong>：大语言模型的研究者发现，通过增加模型的参数量（N）、训练数据量（D）以及计算量（C），模型的性能（L）会随之提升。这意味着，更大的模型通常能处理更复杂的任务，产生更精确的结果。</li><li><strong>幂律关系</strong>：scaling-law揭示了一个重要现象，即模型性能的提升与模型规模（参数量、数据量、计算量）的增加之间存在幂律关系。简单来说，就是当模型规模翻倍时，模型性能的提升幅度可能不仅仅是一倍，而是更高。</li><li><strong>模型结构与性能</strong>：尽管模型的具体结构（如层数、深度、宽度等）对性能有一定影响，但相对于模型规模来说，这些因素的影响较小。在给定足够的模型规模时，不同的结构设计往往能带来相近的性能。</li></ul></blockquote><h2 id="用好ai的核心方法" tabindex="-1"><a class="header-anchor" href="#用好ai的核心方法"><span>用好AI的核心方法</span></a></h2><p>把AI当人看，数字神经网络和人脑的生物神经网络，在数学原理上是一样的。</p><h2 id="大模型应用业务架构" tabindex="-1"><a class="header-anchor" href="#大模型应用业务架构"><span>大模型应用业务架构</span></a></h2><ul><li>AI Embedded 模式：假设有一个流程，针对某一个环节将AI给加进来（人脸识别项目）</li><li>AI Copilot 模式：针对每一个流程，都使用AI加以辅助（代码智能提示）</li><li>AI Agent 模式：用户提出一个要求，直接交给AI，AI自动生成所有的流程，全权交给AI处理事情</li></ul><p>当前的关键：理清业务，拆出SOP。（SOP其实就像是一份详细的“说明书”或“菜谱”，它告诉我们如何一步一步地完成某个任务或操作。）</p><h2 id="大模型应用技术架构" tabindex="-1"><a class="header-anchor" href="#大模型应用技术架构"><span>大模型应用技术架构</span></a></h2><h3 id="纯-prompt" tabindex="-1"><a class="header-anchor" href="#纯-prompt"><span>纯 Prompt</span></a></h3><p>问一句，它回一句。。。</p><figure><img src="'+l+'" alt="image-20240626112716458" tabindex="0" loading="lazy"><figcaption>image-20240626112716458</figcaption></figure><h3 id="agent-function-calling" tabindex="-1"><a class="header-anchor" href="#agent-function-calling"><span>Agent + Function Calling</span></a></h3><ul><li>Agent：AI 主动提要求 <ul><li>这里的 Agent 和前面说的 Agent 模式不一样，这个 Agent 只能提出一个小的问题，不能生成完整的流程</li></ul></li><li>Function Calling：AI 要求执行某个函数。</li><li>举例：你问 ta 过年去哪玩，ta 先问你有多少预算</li></ul><figure><img src="'+r+'" alt="image-20240626112925398" tabindex="0" loading="lazy"><figcaption>image-20240626112925398</figcaption></figure><h3 id="rag-retrieval-augmented-generation" tabindex="-1"><a class="header-anchor" href="#rag-retrieval-augmented-generation"><span>RAG(Retrieval-Augmented Generation)</span></a></h3><ul><li>Embeddings：把文字转换为更易于相似度计算的编码。这种编码叫向量</li><li>向量数据库：把向量存起来，方便查找</li><li>向量搜索：根据输入向量，找到最相似的向量</li><li>举例：考试答题时，到书上找相关内容，再结合题目组成答案，模型不会记忆输入</li></ul><figure><img src="'+o+'" alt="image-20240626154704476" tabindex="0" loading="lazy"><figcaption>image-20240626154704476</figcaption></figure><h3 id="fine-tuning" tabindex="-1"><a class="header-anchor" href="#fine-tuning"><span>Fine-tuning</span></a></h3><figure><img src="'+g+'" alt="image-20240626154823925" tabindex="0" loading="lazy"><figcaption>image-20240626154823925</figcaption></figure><p>适合微调的场景：</p><ol><li>提高模型输出的稳定性</li><li>用户量大，降低推理成本的意义很大</li><li>提高大模型的生成速度</li><li>需要私有部署</li></ol><h2 id="大模型榜单推荐" tabindex="-1"><a class="header-anchor" href="#大模型榜单推荐"><span>大模型榜单推荐</span></a></h2><p><a href="https://lmsys.org/" target="_blank" rel="noopener noreferrer">LMSYS Org</a></p><p><a href="https://arena.lmsys.org/" target="_blank" rel="noopener noreferrer">Chat with Open Large Language Models (lmsys.org)</a></p>',28)]))}const m=t(s,[["render",d],["__file","01-了解认识.html.vue"]]),A=JSON.parse('{"path":"/knowledge/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/01-%E4%BA%86%E8%A7%A3%E8%AE%A4%E8%AF%86.html","title":"了解大模型","lang":"zh-CN","frontmatter":{"description":"了解大模型 AGl(Artificial General inteligence)：通用人工智能 AI可能的问题：幻觉 生成机制 目前只有 transformer 被证明了符合 scaling-law。 定义：Scaling-law（尺度定律）在大语言模型中指的是一种观察到的现象，即当模型规模（如参数量、训练数据量等）增加时，模型的性能（如预测准确性、...","head":[["meta",{"property":"og:url","content":"https://jishuzhaix.cn/knowledge/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/01-%E4%BA%86%E8%A7%A3%E8%AE%A4%E8%AF%86.html"}],["meta",{"property":"og:site_name","content":"技数斋"}],["meta",{"property":"og:title","content":"了解大模型"}],["meta",{"property":"og:description","content":"了解大模型 AGl(Artificial General inteligence)：通用人工智能 AI可能的问题：幻觉 生成机制 目前只有 transformer 被证明了符合 scaling-law。 定义：Scaling-law（尺度定律）在大语言模型中指的是一种观察到的现象，即当模型规模（如参数量、训练数据量等）增加时，模型的性能（如预测准确性、..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-22T12:24:50.000Z"}],["meta",{"property":"article:modified_time","content":"2025-02-22T12:24:50.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"了解大模型\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-22T12:24:50.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"贺墨于\\",\\"url\\":\\"https://jishuzhaix.cn\\"}]}"]]},"headers":[{"level":2,"title":"生成机制","slug":"生成机制","link":"#生成机制","children":[]},{"level":2,"title":"用好AI的核心方法","slug":"用好ai的核心方法","link":"#用好ai的核心方法","children":[]},{"level":2,"title":"大模型应用业务架构","slug":"大模型应用业务架构","link":"#大模型应用业务架构","children":[]},{"level":2,"title":"大模型应用技术架构","slug":"大模型应用技术架构","link":"#大模型应用技术架构","children":[{"level":3,"title":"纯 Prompt","slug":"纯-prompt","link":"#纯-prompt","children":[]},{"level":3,"title":"Agent + Function Calling","slug":"agent-function-calling","link":"#agent-function-calling","children":[]},{"level":3,"title":"RAG(Retrieval-Augmented Generation)","slug":"rag-retrieval-augmented-generation","link":"#rag-retrieval-augmented-generation","children":[]},{"level":3,"title":"Fine-tuning","slug":"fine-tuning","link":"#fine-tuning","children":[]}]},{"level":2,"title":"大模型榜单推荐","slug":"大模型榜单推荐","link":"#大模型榜单推荐","children":[]}],"git":{"createdTime":1739802080000,"updatedTime":1740227090000,"contributors":[{"name":"HeMOu","username":"HeMOu","email":"fangqichenchao@163.com","commits":2,"url":"https://github.com/HeMOu"}]},"readingTime":{"minutes":2.97,"words":890},"filePathRelative":"knowledge/人工智能/大语言模型/基础学习/01-了解认识.md","localizedDate":"2025年2月17日","excerpt":"\\n<blockquote>\\n<p>AGl(Artificial General inteligence)：通用人工智能</p>\\n<p>AI可能的问题：幻觉</p>\\n</blockquote>\\n<h2>生成机制</h2>\\n<table>\\n<thead>\\n<tr>\\n<th>架构</th>\\n<th>设计者</th>\\n<th>特点</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Transformer</td>\\n<td>Google</td>\\n<td>最流行，几乎所有大模型都用它</td>\\n</tr>\\n<tr>\\n<td>RWKV</td>\\n<td>PENG BO</td>\\n<td>可并行训练，推理性能极佳，适合在端侧使用</td>\\n</tr>\\n<tr>\\n<td>Mamba</td>\\n<td>CMU &amp; Princeton University</td>\\n<td>性能更佳，尤其适合长文本生成</td>\\n</tr>\\n</tbody>\\n</table>","autoDesc":true}');export{m as comp,A as data};
